===================

BIGQUERY:

>> Bigquery arch
   storage and compute - decoupled/isolated (cost efficient)
   layers:
   colossus - is google distributed file system storage layer in column orientaed - fault tolerance by data replicas across different machines.
   dremel - is compute engine - have root server (co-ordinate mixers & leaf nodes) / mixers (do aggreagtions) / leaf nodes (read data from storage)
   jupiter- high speed n/w connector - to connect dremel with colossus
   borg - scheduling jobs like run queries

>> 
DDL(Data Definition Language) â€“ define structure/schema of database (Create/alter/drop/truncate)
DML(Data Manipulation Language) â€“ manipulate data (Insert/update/delete/merge)
DQL(Data Query Language) â€“ select 
TCL(Transaction Control Language) â€“ commit transaction and role back in case of any errors
DCL(Data Control Language) â€“ for security and access control 

>> Sql query execution order: From / where / group by / having / select / distinct / order by / limit
select 5 /distict 6 / from table 1 / where 2 / group by 3 / having 4/ order by 7 / limit 8

>> conversion functions:
   The CAST function performs a conversion between compatible data types. 
   If the conversion fails due to data type incompatibility or data loss, the query will fail
   The SAFE_CAST function also performs a conversion between compatible data types, 
   but it handles conversion errors differently. Instead of failing the query, it returns NULL when the conversion cannot    be performed.

>> commenting: -- or # or /* LINES */

>> Create table with metadata from existing table â€“ use where 1 = 2 or false

>> .
   SELECT * EXCEPT(column1, column2, ...) FROM table_name; 
   SELECT DISTINCT department FROM employees limit 10;
   SELECT ROUND(56.14159, -2/-1); / SELECT ROUND(56.14159, 2); /

>> String functions:
CONCAT('#', LTRIM('   apple   '), '#') / LENGTH('suresh') / SPLIT('apple,banana,orange', ',') / REPEAT('abc', 3) / REVERSE('abc') / REPLACE ('desert pie', 'pie', 'cobbler') 
INSTR('banana', 'an', 1, 1) / STRPOS('foo@example.com', '@') 
LEFT('banana', 3) / RIGHT('apple', 3) / SUBSTR('apple', 2, 2) / SUBSTRING alias for SUBSTR /
LOWER('FOO BAR BAZ') / UPPER('foo')
LTRIM('   apple   ') / RTRIM('***apple***', '*') / TRIM( '   apple   ') /
STARTS_WITH('bar', 'b') / ENDS_WITH('apple', 'e') / CONTAINS_SUBSTR('the blue house', CONCAT('Blue ', 'house')) / 

>> Union all / Union distinct / Table wildcards: test_*` where _Table_Suffix > 5 / Except distinct / Intersect distinct /

>>   Permanent table: save query results on BQ storage
   Temporary table/cache â€“ Query results saved on cache and valid for 24 hrs.
   Internal/native table/managed tables: table in BQ storage
   External table: BQ querying data from bigtable, gcs, google drive

>> Time travel concept: Query the state of the table as it was at a specific timestamp

>> Creation of view/materialized view and auth view: efficiently manage and secure your data access in BigQuery
   Create view: virtual tables / view hits base table and display data / frequent updates on base table/ infrequent data       access / 
   Materialized view: data stored on disk / better performance/ frequent access on data / infrequent updates on base table /
   Authorized views and authorized materialized views: let you share query results with particular users and groups without    giving them access to the underlying source data.

>> Partitioning and clustering:
   Improved Query Performance: By scanning only relevant partitions and clustered blocks, queries run faster.
   Cost Efficiency: Reduced data scanned means lower costs, as BigQuery charges based on the amount of data processed.

>> Joins: -  combine rows from two or more tables based on a related column between them.
   INNER JOIN / left join / right join / full join / cross join / self join /
   Best Practices for Joins in BigQuery: Use Appropriate Join Types: / Filter Early / Avoid Cross Joins When Possible / 
   Use Partitioned and Clustered Tables: If joining large tables / Monitor Query Performance /

>> With statement: also known as Common Table Expressions (CTEs), allows you to define temporary result sets.
   Adv: code more readable, resusebility - referenced in several places within the main SQL query. 

>> Conditions:
If condition
then
sql statement;
end if;

for var in list
do 
sql statement;
end for;

/ labels /repeat / while /leave/ break/ continue/ iterate 

>> Pivoting and unpivoting: help in reshaping your data for analysis or reporting
   Pivot: row into columns
   unpivot: columns into rows

>> Normalization â€“ avoid redundant data (lesser storage costs)- poor query performance (joining tables)
   De Normalization â€“ redundant data (high storage cost) â€“ better Query performance 
   Why array & structs? â€“ for better query per and lesser storage costs
   
   Arrays â€“ list of items having same data type
   SELECT element FROM mydataset.mytable, UNNEST(my_array) AS element;

   Struct â€“ record with nested fields having different data types
   SELECT person.id, person.name FROM mydataset.mytable;
 
>> Window functions: performing advanced calculations over a set of rows, go beyond simple aggregates or filters
   max(cn) / min(cn) / count(cn) / sum(cn) / avg(cn) /row_number() / rank() / dense_rank() 
   SUM(column2) OVER (PARTITION BY column1 ORDER BY column2 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rt
   lag(cn) / lead(cn): Accesses data from a previous or subsequent row in the same result set without use of a self-join.
   LAG(column2, 1) OVER (PARTITION BY column1 ORDER BY column2) AS previous_value,
   first_value(cn) / last_value(cn) / nth_value(cn, n) 
   FIRST_VALUE(column2) OVER (PARTITION BY column1 ORDER BY column2) AS first_value,
   ntile(n) â€“ n groups 
   NTILE(4) OVER (PARTITION BY column1 ORDER BY column2) AS quartile
   cum_dist() / percent_rank() 
   CUME_DIST= NumberÂ ofÂ rowsÂ withÂ valuesÂ lessÂ thanÂ orÂ equalÂ toÂ theÂ currentÂ row / TotalÂ numberÂ ofÂ rows
â€‹   PERCENT_RANK= RankÂ ofÂ currentÂ rowâˆ’1 / TotalÂ rowsâˆ’1
â€‹   Rows consider current row even if duplicates / range considers bottom row of duplicates.

>> Regular expressions: used for pattern matching and string manipulation
   REGEXP_CONTAINS(column_name, r'pattern')
   REGEXP_EXTRACT_ALL(column_name, r'pattern')
   REGEXP_REPLACE(column_name, r'pattern', 'replacement')
   SPLIT(column_name, r'pattern')

>> Big Query cost optimization
   -- bq compute optimization: on-demaned analysis, bq editions - decide based on your workloads.
   
   -- BQ data storage â€“ 
   Billing model: logical- data in uncompressed format/ physical- data in compressed format) 
   Use Table Expiration Settings 
   Optimize Data Storage Format (cloumner format - paqruet. ORC)
   Use Long-Term Storage Pricing (> 90 days)

   -- Query optimization 
   create dataset in region wehere customer operates
   Use Partitioned Tables and Clustered Tables
   use avro format to bigquery data load - google rec compressed avro for quick data load
   use preview option for bq native table
   select columns instead of *
   use truncate instead of delete
   nest repeated data, Denormalize Data Where Appropriate (Use ARRAY Functions for Multi-Value Fields)
   Join pattern larger table join smaller tables, Optimize JOIN Operations, avoid cross join
   where class first condition in such way that eliminates most data
   late aggregation
   Use WITH Clauses for Subquery Caching (Avoid Repeated Scalar Subqueries)
   Take Advantage of Query Caching
   Aggregate Data at the Source: Use Approximate Aggregations: 
   Create a materialized view based on frequently run queries.
   Optimize Window Functions
   Monitor and Tune Query Performance
  
   -- Cost Controls: 
   Set quotas and budget alerts
   set query limits
   Analyze Cost Breakdown Using Cloud Billing Reports
   bq compute cost analysis
   bq query optimi
   bq storage cost opti
   Schedule queries during off-peak hours to take advantage of low on-demand pricing typically at mid-night/early morning

>> To find the department names where no employees are found, you can use the following SQL query:
   emp -->> employee_id	employee_name	dept_id
   Department Table -->> dept_id	dept_name
   SELECT d.dept_name FROM dept d LEFT JOIN employee e ON d.dept_id = e.dept_id WHERE e.dept_id IS NULL;
   

====================================================================================================================================================

SQL QA:
>> Given two tables, find the count of records for Left Outer Join and Inner Join:
Table A: Table B:
1 1
1 1
1 1 
1 
Ans. 12 & 12
>> Give the output for DENSE_RANK() and RANK() functions for the below dataset:
Nums 
85 
85 
80 
75 
75 
70

>> Given a table with column 'Country', select data in the below sequence:
Table: Matches
Country 
India 
Australia 
Pakistan 
Output:
India vs Australia 
India vs Pakistan 
Australia vs Pakistan
Ans. 
    SELECT a.countryc || ' vs ' || b.countryc as country
    FROM
      `powerful-layout-445408-p5.sur_test_ds.countryt` a
    join
      `powerful-layout-445408-p5.sur_test_ds.countryt` b
    on a.countryc > b.countryc;  -----> or <
>> Given two tables, output the result of INNER, LEFT, RIGHT, FULL JOINS.
Table1:
col1 
---- 
1 
1 
Table2:
---- 
b 
a 
1 
>> Find the 777th highest salary from a table.
ðŸ”¹ Identify customers who placed orders in consecutive months.
ðŸ”¹ Query to get the total number of patients per doctor, including unassigned patients.
>> Handling NULL values in employee salary using the average salary.
    IFNULL(expression, replacement_value) -->> It takes two arguments. If the first argument is NULL, it returns the second argument.
    COALESCE(expression1, expression2, ..., expressionN) -->> It can take multiple arguments. It returns the first non-NULL argument from the list.
>> Difference between Subquery and Materialized Views.
    Performance: Materialized views can improve query performance by storing precomputed results, while subqueries are recalculated each time the main query runs.
    Storage: Materialized views consume storage space to store the precomputed results, whereas subqueries do not.
    Maintenance: Materialized views need to be refreshed to stay up-to-date with the underlying data, while subqueries always reflect the current state of the data.
>> CTE vs Subquery in SQL and their performance impact.
    Readability and Maintainability:
    Optimization: Subquery Treated similarly to CTEs in terms of optimization. The query optimizer will attempt to optimize the entire query, including the subqueries.
    Reusability:
ðŸ”¹ Steps to debug a slow SQL query.



